{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "**NOTE** This is pretty unstable in the sense that:\n",
    "\n",
    "- It is based on the static Qualtrics output.\n",
    "- The LP survey is still in flux - we don't know what the final qualitative questions will be.\n",
    "- The \"expected themes\" have not been decided upon...\n",
    "- ... Which means that we don't know which qualitative answers are important...\n",
    "- ... Which means we haven't yet tagged the actual course content to see how these generated topics will map.\n",
    "\n",
    "** *In this context, the code below is more \"proof-of-concept\" than anything else.* ** \n",
    "\n",
    "\n",
    "However, here's how it generally works:\n",
    "\n",
    "1. Read in raw data and clean it (remove NaNs, format text)\n",
    "2. Create \"documents\" based on qualitative answers. Questions (and their answers) will eventually be grouped together based on similarity (eg, three questions that ask about goals or values). *This is a decision that needs to be made by TLL - once it is made those question names can be hard-coded in.*\n",
    "3. Perform LDA (for more info, see http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html)\n",
    "4. Use the 3 most salient words from each topic as a \"tag\" (eg \"education-global-policy\")\n",
    "5. Compare the distance of each document to each topic - the topic that a doc is 'closest' defines that doc's tag.\n",
    "6. Add column of tags back to original data.\n",
    "7. Export data.\n",
    "\n",
    "**What feeds the recommendation/adaptive engine?**\n",
    "\n",
    "This is all based on the assumption that the final tags (eg, \"education-global-policy\") will be what informs VPAL. However, since we do not know what the final questions will actually be, we can't say for sure what the topics may end up being. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from simhash import Simhash\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean docs (lowercase, remove punctuation)\n",
    "def clean_docs(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w]', ' ', s)\n",
    "    return s\n",
    "\n",
    "# clean and make docs\n",
    "def make_docs(cols,df):\n",
    "    docs = []\n",
    "    rows = df.shape[0]\n",
    "    small = df[cols]\n",
    "    \n",
    "    for row in range(2,rows):\n",
    "        temp = [str(i) for i in small.loc[row] if len(str(i)) > 3]\n",
    "        joined = \" \".join(temp)\n",
    "        cleaned = clean_docs(joined)\n",
    "        \n",
    "        docs.append(cleaned)\n",
    "        \n",
    "    return docs\n",
    "\n",
    "# this returns a dictionary of topics/themes, each entry is \n",
    "# a list of the 20 most salient words for that topic\n",
    "def get_topics(model, feature_names, no_top_words = 20):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topics[\"Topic{}\".format(topic_idx)] = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "    return topics\n",
    "\n",
    "\n",
    "# Do the actual topic modeling, return the topics\n",
    "def do_lda(docs, topics = 4, no_features = 1000):\n",
    "    \n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(docs)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_topics=topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "    lda.fit(tf)\n",
    "    \n",
    "    topics = get_topics(lda, tf_feature_names)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# How far away is each answer from each topic?\n",
    "def get_distances(topics,docs):\n",
    "    final_dist = []\n",
    "    for text in docs:\n",
    "        temp_dist = []\n",
    "        for key in topics.keys():\n",
    "            temp_dist.append(Simhash(topics[key]).distance(Simhash(text)))\n",
    "        final_dist.append(np.argmin(temp_dist))\n",
    "    return final_dist\n",
    "\n",
    "# Based on that distance, what topic does each answer belong to?\n",
    "def tag_docs(final_d, topics):\n",
    "    tagged = []\n",
    "    keys = list(topics.keys())\n",
    "    for i in final_d:\n",
    "        tagged.append(\"-\".join(topics[keys[i]].split()[0:3]))\n",
    "\n",
    "    return tagged\n",
    "\n",
    "# join the list of tags to the original data\n",
    "def tag_on_df(original_df,name,tags):\n",
    "    filler = [\"\",\"\"] # this is for a Qualtrics annoyance\n",
    "    final_tags = filler+tags\n",
    "    new_df = original_df.copy()\n",
    "    new_df[name] = final_tags\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the above\n",
    "def final_analysis(original_df,columns,name):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    docs = make_docs(columns,original_df)\n",
    "    topics = do_lda(docs)\n",
    "    distances = get_distances(topics,docs)\n",
    "    tags = tag_docs(distances,topics)\n",
    "    final_df = tag_on_df(original_df,name,tags)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  00:00:05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Email</th>\n",
       "      <th>Program</th>\n",
       "      <th>MailingState</th>\n",
       "      <th>MailingCountry</th>\n",
       "      <th>PermState</th>\n",
       "      <th>PermCountry</th>\n",
       "      <th>HowConfident</th>\n",
       "      <th>Q237_1 - Topics</th>\n",
       "      <th>GoalsAndValues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start Date</td>\n",
       "      <td>End Date</td>\n",
       "      <td>Response Type</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>Progress</td>\n",
       "      <td>Duration (in seconds)</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Recorded Date</td>\n",
       "      <td>Response ID</td>\n",
       "      <td>Recipient Last Name</td>\n",
       "      <td>...</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Email</td>\n",
       "      <td>Program</td>\n",
       "      <td>MailingState</td>\n",
       "      <td>MailingCountry</td>\n",
       "      <td>PermState</td>\n",
       "      <td>PermCountry</td>\n",
       "      <td>HowConfident</td>\n",
       "      <td>Q237_1 - Topics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"ImportId\":\"startDate\",\"timeZone\":\"America/De...</td>\n",
       "      <td>{\"ImportId\":\"endDate\",\"timeZone\":\"America/Denv...</td>\n",
       "      <td>{\"ImportId\":\"status\"}</td>\n",
       "      <td>{\"ImportId\":\"ipAddress\"}</td>\n",
       "      <td>{\"ImportId\":\"progress\"}</td>\n",
       "      <td>{\"ImportId\":\"duration\"}</td>\n",
       "      <td>{\"ImportId\":\"finished\"}</td>\n",
       "      <td>{\"ImportId\":\"recordedDate\",\"timeZone\":\"America...</td>\n",
       "      <td>{\"ImportId\":\"_recordId\"}</td>\n",
       "      <td>{\"ImportId\":\"recipientLastName\"}</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"ImportId\":\"Gender\"}</td>\n",
       "      <td>{\"ImportId\":\"Email\"}</td>\n",
       "      <td>{\"ImportId\":\"Program\"}</td>\n",
       "      <td>{\"ImportId\":\"MailingState\"}</td>\n",
       "      <td>{\"ImportId\":\"MailingCountry\"}</td>\n",
       "      <td>{\"ImportId\":\"PermState\"}</td>\n",
       "      <td>{\"ImportId\":\"PermCountry\"}</td>\n",
       "      <td>{\"ImportId\":\"HowConfident\"}</td>\n",
       "      <td>{\"ImportId\":\"QID237_1_c7de10f363ca498aa380d2f8...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-14 20:11:34</td>\n",
       "      <td>2017-08-14 22:04:53</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>108.91.186.96</td>\n",
       "      <td>100</td>\n",
       "      <td>6799</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-08-14 22:04:54</td>\n",
       "      <td>R_31veOCGegzf0DXr</td>\n",
       "      <td>Poikonen</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mind, Brain &amp; Education</td>\n",
       "      <td>MN</td>\n",
       "      <td>USA</td>\n",
       "      <td>MN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>education-students-teaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-14 16:00:06</td>\n",
       "      <td>2017-08-15 15:58:22</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>104.61.162.88</td>\n",
       "      <td>100</td>\n",
       "      <td>86295</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-08-15 15:58:24</td>\n",
       "      <td>R_8bNEEDUOMcpxtbH</td>\n",
       "      <td>Woo</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mind, Brain &amp; Education</td>\n",
       "      <td>CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>education-school-teaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-14 12:16:06</td>\n",
       "      <td>2017-08-16 14:19:25</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>65.112.8.131</td>\n",
       "      <td>100</td>\n",
       "      <td>180199</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-08-16 14:19:27</td>\n",
       "      <td>R_0MqvbG3q3AbYh45</td>\n",
       "      <td>Wu</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology, Innovation &amp; Educ</td>\n",
       "      <td>11</td>\n",
       "      <td>CHN</td>\n",
       "      <td>11</td>\n",
       "      <td>China</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>people-school-try</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           StartDate  \\\n",
       "0                                         Start Date   \n",
       "1  {\"ImportId\":\"startDate\",\"timeZone\":\"America/De...   \n",
       "2                                2017-08-14 20:11:34   \n",
       "3                                2017-08-14 16:00:06   \n",
       "4                                2017-08-14 12:16:06   \n",
       "\n",
       "                                             EndDate                 Status  \\\n",
       "0                                           End Date          Response Type   \n",
       "1  {\"ImportId\":\"endDate\",\"timeZone\":\"America/Denv...  {\"ImportId\":\"status\"}   \n",
       "2                                2017-08-14 22:04:53             IP Address   \n",
       "3                                2017-08-15 15:58:22             IP Address   \n",
       "4                                2017-08-16 14:19:25             IP Address   \n",
       "\n",
       "                  IPAddress                 Progress    Duration (in seconds)  \\\n",
       "0                IP Address                 Progress    Duration (in seconds)   \n",
       "1  {\"ImportId\":\"ipAddress\"}  {\"ImportId\":\"progress\"}  {\"ImportId\":\"duration\"}   \n",
       "2             108.91.186.96                      100                     6799   \n",
       "3             104.61.162.88                      100                    86295   \n",
       "4              65.112.8.131                      100                   180199   \n",
       "\n",
       "                  Finished                                       RecordedDate  \\\n",
       "0                 Finished                                      Recorded Date   \n",
       "1  {\"ImportId\":\"finished\"}  {\"ImportId\":\"recordedDate\",\"timeZone\":\"America...   \n",
       "2                     True                                2017-08-14 22:04:54   \n",
       "3                     True                                2017-08-15 15:58:24   \n",
       "4                     True                                2017-08-16 14:19:27   \n",
       "\n",
       "                 ResponseId                 RecipientLastName  \\\n",
       "0               Response ID               Recipient Last Name   \n",
       "1  {\"ImportId\":\"_recordId\"}  {\"ImportId\":\"recipientLastName\"}   \n",
       "2         R_31veOCGegzf0DXr                          Poikonen   \n",
       "3         R_8bNEEDUOMcpxtbH                               Woo   \n",
       "4         R_0MqvbG3q3AbYh45                                Wu   \n",
       "\n",
       "              ...                              Gender                 Email  \\\n",
       "0             ...                              Gender                 Email   \n",
       "1             ...               {\"ImportId\":\"Gender\"}  {\"ImportId\":\"Email\"}   \n",
       "2             ...                              Female                   NaN   \n",
       "3             ...                              Female                   NaN   \n",
       "4             ...                              Female                   NaN   \n",
       "\n",
       "                         Program                 MailingState  \\\n",
       "0                        Program                 MailingState   \n",
       "1         {\"ImportId\":\"Program\"}  {\"ImportId\":\"MailingState\"}   \n",
       "2        Mind, Brain & Education                           MN   \n",
       "3        Mind, Brain & Education                           CA   \n",
       "4  Technology, Innovation & Educ                           11   \n",
       "\n",
       "                  MailingCountry                 PermState  \\\n",
       "0                 MailingCountry                 PermState   \n",
       "1  {\"ImportId\":\"MailingCountry\"}  {\"ImportId\":\"PermState\"}   \n",
       "2                            USA                        MN   \n",
       "3                            USA                        CA   \n",
       "4                            CHN                        11   \n",
       "\n",
       "                  PermCountry                 HowConfident  \\\n",
       "0                 PermCountry                 HowConfident   \n",
       "1  {\"ImportId\":\"PermCountry\"}  {\"ImportId\":\"HowConfident\"}   \n",
       "2               United States               Very confident   \n",
       "3               United States               Very confident   \n",
       "4                       China               Very confident   \n",
       "\n",
       "                                     Q237_1 - Topics  \\\n",
       "0                                    Q237_1 - Topics   \n",
       "1  {\"ImportId\":\"QID237_1_c7de10f363ca498aa380d2f8...   \n",
       "2                                            Unknown   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                GoalsAndValues  \n",
       "0                               \n",
       "1                               \n",
       "2  education-students-teaching  \n",
       "3    education-school-teaching  \n",
       "4            people-school-try  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE:\n",
    "\n",
    "data = pd.read_csv(\"master.csv\")\n",
    "question_cols = [\"Q414\", \"Q240\", \"Q241\"] #these questions have to do with goals and values\n",
    "\n",
    "new_data = final_analysis(data,question_cols,\"GoalsAndValues\")\n",
    "new_data.head()\n",
    "\n",
    "# new_data.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
