{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initial LDA.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DqC_sY4IcVEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LDA for qualitative groups\n",
        "\n",
        "This code generates the initial lda model that will eventually be used by the LPD. It requires a human to interpret the topics. You may want to run this multiple times until the topics become interpretable - once they do, save the lda model."
      ]
    },
    {
      "metadata": {
        "id": "UanskshUcVEl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import re\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pyfieOcddntO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Functions**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5yVyDWl5cVEn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# clean docs (lowercase, remove punctuation)\n",
        "def clean_docs(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[^\\w]', ' ', s)\n",
        "    return s\n",
        "\n",
        "# clean and make docs\n",
        "def make_docs(cols,df):\n",
        "    docs = []\n",
        "    rows = df.shape[0]\n",
        "    small = df[cols]\n",
        "    t = [\"teaching\",\"teacher\",\"teachers\"] # will reduce all instances of \"teach-\" to \"teach\" \n",
        "    \n",
        "    for row in range(2,rows):\n",
        "        temp = [str(i) for i in small.loc[row] if len(str(i)) > 3]\n",
        "        joined = \" \".join(temp)\n",
        "        clean = clean_docs(joined)\n",
        "        \n",
        "        words = word_tokenize(clean)\n",
        "        \n",
        "        cleaner = [i if i not in t else \"teach\" for i in words]\n",
        "        cleaner = \" \".join(cleaner)\n",
        "\n",
        "        docs.append(cleaner)\n",
        "        \n",
        "    return docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g77pMznFcVEp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "outputId": "7ee78d55-e6ce-43a8-f164-6808c4b41251"
      },
      "cell_type": "code",
      "source": [
        "# Read in the data, identify columns of interest\n",
        "\n",
        "data = pd.read_csv(\"hplsurvey.csv\")\n",
        "\n",
        "# IMPORTANT: 'qual_cols' needs to be re-written with the names of the columns from the LPD\n",
        "# current column names are just from qualtrics.\n",
        "qual_cols = ['Q3','Q5','Q6','Q15','Q36','Q36_5_TEXT','Q46',\n",
        " 'Q10',\n",
        " 'Q11',\n",
        " 'Q12','Q18',\n",
        " 'Q19',\n",
        " 'Q20']\n",
        "\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "# added student answers about jobs (technically multiple choice, but gives important info)\n",
        "plus_job = qual_cols+['Q15','Q12','Q46']\n",
        "qualitative_data = data[plus_job]\n",
        "\n",
        "# NAs will cause errors\n",
        "qualitative_data.fillna(\"\",inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py:3035: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  downcast=downcast, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5JmuejPcVEt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# combine answers of all respondents so we can do LDA\n",
        "docs = make_docs(list(qualitative_data.columns),qualitative_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eR475I0cVEv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create a tfidf matrix (sparse word frequency matrix)\n",
        "tfidf = TfidfVectorizer(max_features = 1000,stop_words = 'english')\n",
        "\n",
        "# add words to ignore (eg, if 'education' is not ignored, it dominates all topics)\n",
        "# this list of words should change each year (ie when the code is rerun for 2019, etc)\n",
        "stops = list(tfidf.get_stop_words()) +['education','students','students','school','learning','learn','gt','experience',\"teach\",\"working\"]\n",
        "tfidf.set_params(stop_words=stops)\n",
        "X = tfidf.fit_transform(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJ3n5LVqcVEy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "outputId": "264fd6d3-ae97-4e67-b7b7-cf88743381b0"
      },
      "cell_type": "code",
      "source": [
        "tfidf_names = tfidf.get_feature_names()\n",
        "\n",
        "lda = LatentDirichletAllocation(n_topics = 7, max_iter = 10, learning_method='online',learning_offset=.5)\n",
        "\n",
        "# Because lda works on randomness, you might want to know what random seed python was using, for reproducability.\n",
        "print(np.random.get_state()[1][0])\n",
        "group_probs = lda.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232220589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Pg2VFc9cVE1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "outputId": "eb1c13b9-1280-43f7-d2d7-8ad101e63a3a"
      },
      "cell_type": "code",
      "source": [
        "# This is how you will make the group tags. Requires a human to make sense of the topics.\n",
        "# This also where you may notice words you want to include in the stopword list.\n",
        "topics = {}\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    topics[\"Topic{}\".format(topic_idx)] = \" \".join([tfidf_names[i]\n",
        "        for i in topic.argsort()[:-10 - 1:-1]])\n",
        "topics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Topic0': 'facilitating creating independently people established promote helping media organization institution',\n",
              " 'Topic1': 'directly creating term justice social knowledge learners equity support harvard',\n",
              " 'Topic2': 'early research technology want creating based design impact like tools',\n",
              " 'Topic3': 'educator cried strain background lifetime aspect potential effective slowing sustainable',\n",
              " 'Topic4': 'evaluation equity colleges step leadership programs methods promoting justice making',\n",
              " 'Topic5': 'directly learners making creating promoting equity producing make succeed inspiring',\n",
              " 'Topic6': 'leadership want student institutions social higher ways development manage management'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "AVCGIvf5cVE3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "outputId": "63eb3b85-ce96-4e3c-b590-187289ee0fe5"
      },
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "# protocol 2 is compatible with python 2.x\n",
        "# lda.pkl is the file name, you can point to whatever file path\n",
        "joblib.dump(lda, 'lda.pkl', protocol = 2) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lda.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "5y3vVnfucVE9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjAKquE6cVE-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}