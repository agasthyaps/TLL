{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the raw data\n",
    "\n",
    "- similarity info (from survey) and registrant doc (from my.harvard) are encoded differently, set up differently, etc SO:\n",
    "    - *For the Registrant Doc*\n",
    "        - resave the registrant doc to be utf-8\n",
    "        - ensure that pd.read_csv is *tab-delimited* (*eye roll emoji*)\n",
    "        - concatenate the Last, First column in info so we can actually compare the two dataframes\n",
    "        - join them\n",
    "        - extract relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity info, from the interest survey\n",
    "info = pd.read_csv('info copy.txt')\n",
    "\n",
    "# Actual registrants, from my.harvard\n",
    "people = pd.read_csv('finalroster copy.txt',delimiter='\\t')\n",
    "\n",
    "# select important columns\n",
    "info = info[list(info.columns[:11])]\n",
    "\n",
    "# this student's last name got encoded strangely (because of the accent), so we fix it\n",
    "info.loc[19,'Last'] = 'BÃ©land'\n",
    "\n",
    "# take a peek at what the my.harvard export looks like\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info has a TON of extra empty lines (like thousands of them)\n",
    "# so let's drop them\n",
    "info.dropna(how=\"all\",inplace=True)\n",
    "\n",
    "# Since the similarity info has two separate fields for first and last name, but the my.harvard export has one name field formatted as \"Last,First\"\n",
    "# we should change formatting so that it matches.\n",
    "name = []\n",
    "for idx in list(info.index):\n",
    "    concat = info.loc[idx][\"Last\"]+','+info.loc[idx][\"First\"]\n",
    "    name.append(concat)\n",
    "    \n",
    "info[\"Name\"] = name\n",
    "\n",
    "# once we join the two data sets, we want to be able to identify the people who are actually registered\n",
    "# so make a 'Reg' field that = T(rue) for registrants\n",
    "people[\"Reg\"] = [\"T\" for i in range(people.shape[0])]\n",
    "\n",
    "# join the two data sets\n",
    "both = people.set_index(\"Name\").join(info.set_index(\"Name\"))\n",
    "\n",
    "# check to see if we retained the right number of registrants post-joining\n",
    "both[both.Reg == 'T'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we had initially set the name field as the index, change it back to numbers\n",
    "both.reset_index(inplace=True)\n",
    "\n",
    "# take a peek at what our final dataset looks like\n",
    "both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# someone was missing, add them in\n",
    "both = both.append(info.loc[26],ignore_index=True)\n",
    "\n",
    "# identify the relevant columns\n",
    "data = both[[\"Name\",\"Email Address\", \"Final Concentration (Abbr)\",\"Years Full-Time Employment\",\"Current Work Environment\"]]\n",
    "new_cols = ['name','email','program','employment','sector']\n",
    "data.columns = new_cols\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINALLY CLEAN!!**\n",
    "\n",
    "--------\n",
    "\n",
    "### Cohort Building Functions\n",
    "Below are the functions that actually create the cohorts.\n",
    "\n",
    "**sim_groups**\n",
    "\n",
    "Despite this function's name, it can create groups of similar people, dissimilar people, or a mixed bag. It does this by calculating the cosine similarity (https://en.wikipedia.org/wiki/Cosine_similarity), and then ordering students based on their similarity to a random \"seed\" student. For similar groups, we take the first X students in the ordered list. For dissimilar groups, we take the *last* X students from the list. For mixed groups, we take X/2 from the top of the list, and X/2 from the bottom. The function itself returns a list of indeces which correspond to an entry in the dataframe we created above.\n",
    "\n",
    "**make_soup**\n",
    "\n",
    "\"Soup\" here means creating a long-ish vector (or \"soup\") for each student of all the information we have on them. This vector is then used to calculate the cosine similarity between students in the `sim_groups` function. Additionally, we add a clustering prediction to the information we have. Clusters are based on program, employment, and sector, with double weighting on program and sector. These cluster assignments are **not** cohort assignments; the clusters merely give the cohort builder more information when calculating the cosine similarity so we can hopefully have more precise or \"refined\" groups. This is all based on hypothesis, so it will be interesting to see the results after the course is finished.\n",
    "\n",
    "\n",
    "**make_groups**\n",
    "\n",
    "This function preprocesses some of the data, then calls `make_soup` and `sim_groups` so a user only has to do one function call overall. The preprocessing step is label encoding - this means converting categorical data (like \"program\") into numerical data. This means that in the `make_soup` function, those vectors are all made up of numbers, rather than a combination of words and numbers.\n",
    "\n",
    "For the \"balanced\" groups, we have a different set of functions.\n",
    "\n",
    "**get_ratios**\n",
    "\n",
    "This function finds the distribution of programs within the group of registrants and returns the distribution as a set of ratios. These ratios are what the balanced cohorts will be based on - for example, if in the total registrant set, .3 students are in EPM, each balanced cohort will also have ~.3 students in EPM.\n",
    "\n",
    "**make_balanced_groups**\n",
    "\n",
    "This function uses the ratios from `get_ratios` to creat a set of cohorts that reflect the make up of the entire registrant class. It also tries to ensure that there are no \"lone\" students; that is, there are no cohorts in which a student does not have at least one other person in their program to connect with. This means that even in the balanced cohorts, there may be a slight variation in program distribution compared to the overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function makes groups of people based on cosine (dis)similarity\n",
    "# kind can be \"sim\", \"dis\", or \"mix\" (default is \"sim\")\n",
    "def sim_groups(num_groups, names_list, soup_mat, og_df, kind = \"sim\"):\n",
    "    \n",
    "    names = names_list.copy()\n",
    "    pull = og_df\n",
    "    indices = pd.Series(og_df.index, index=names)\n",
    "    soup_df = pd.DataFrame(soup_mat, index = og_df.index)\n",
    "    \n",
    "    \n",
    "    groups = {}\n",
    "    \n",
    "    for g in range(num_groups):\n",
    "        \n",
    "        soup = soup_df.values\n",
    "        idx = indices[names.loc[random.choice(names.index)]]\n",
    "        cosine_sim = cosine_similarity(soup,soup)\n",
    "        cos_df = pd.DataFrame(cosine_sim, index=names.index, columns = names.index)\n",
    "        sim_scores = cos_df.loc[idx]\n",
    "        sim_scores = sim_scores.sort_values(ascending=False)\n",
    "        \n",
    "        # Change the indexing here to change group sizes \n",
    "        if kind == \"sim\": \n",
    "            student_indices = list(sim_scores[1:15].index)\n",
    "        elif kind == \"dis\":\n",
    "            student_indices = list(sim_scores[-14:].index)\n",
    "        elif kind == \"mix\":\n",
    "            student_indices = list(sim_scores[1:7].index) + list(sim_scores[-8:].index)\n",
    "\n",
    "        \n",
    "        group_idx = student_indices+[idx]\n",
    "#         group = pull[['firstname','lastname']].loc[group_idx]\n",
    "        groups[\"Cohort{}\".format(g)] = group_idx\n",
    "        \n",
    "        # update email list\n",
    "        names.drop(group_idx,inplace=True)\n",
    "\n",
    "        \n",
    "        # update soup_df\n",
    "        soup_df.drop(group_idx,inplace=True)\n",
    "        \n",
    "#         seed = random.choice(list(emails.index))\n",
    "\n",
    "\n",
    "    # Return the groups\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df should have columns 'name', 'program','employment','sector'\n",
    "def make_soup(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "\n",
    "    km = KMeans(n_clusters = 4)\n",
    "    clus = km.fit_predict(df[['program','program','employment','sector','sector']])\n",
    "    df['cluster'] = clus\n",
    "    \n",
    "    soup = []\n",
    "    for ind in list(df.index):\n",
    "        soup.append([int(i) for i in df[['program','employment','sector','cluster']].loc[ind,:]])\n",
    "    \n",
    "    soup_matrix = np.asarray(soup)\n",
    "    \n",
    "    return soup_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups(num_groups,frame, kind = \"sim\"):\n",
    "    \n",
    "    df = frame.copy()\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    prog = le.fit_transform(df.program)\n",
    "    df['program'] = prog\n",
    "    \n",
    "    sec = le.fit_transform(df.sector.astype(str))\n",
    "    df['sector'] = sec\n",
    "    \n",
    "    sm = make_soup(df)\n",
    "    \n",
    "    names = df.name\n",
    "    \n",
    "    g = sim_groups(num_groups,names,sm,df,kind)\n",
    "    \n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratios(df):\n",
    "    prog_ratios = {}\n",
    "    program_list = sorted(list(df.program.unique()))\n",
    "    for prog in program_list:\n",
    "        counter = 0\n",
    "        for idx in list(data.index):\n",
    "            if data.loc[idx].program == prog:\n",
    "                counter += 1\n",
    "        prog_ratios[\"{}\".format(prog)] = counter/data.shape[0]\n",
    "    \n",
    "    return prog_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on a dictionary of ratios\n",
    "def make_balanced_groups(size,df,num_cohorts = 8):\n",
    "    \n",
    "    frame = df.copy()\n",
    "    \n",
    "    ratios = get_ratios(frame)\n",
    "    programs = [key for key in ratios]\n",
    "    \n",
    "    ideal_count = {}\n",
    "    for key in ratios:\n",
    "        ideal_count['{}'.format(key)] = int(ratios[key]*size)\n",
    "    \n",
    "    cohorts = {}\n",
    "    for i in range(num_cohorts):\n",
    "        cohorts['Cohort{}'.format(i+1)] = []\n",
    "    \n",
    "    for cohort in cohorts:\n",
    "        indeces = []\n",
    "        random.shuffle(programs)\n",
    "        for key in programs:\n",
    "            num = ideal_count[key]\n",
    "            if frame[frame.program == key].shape[0] == 3:\n",
    "                num = 3\n",
    "            elif num == 1:\n",
    "                num += 1\n",
    "            elif num == 0:\n",
    "                num += 2\n",
    "            if frame[frame.program == key].shape[0] >= num:\n",
    "                students = list(frame[frame.program == key].sample(n = num).index.values)\n",
    "                frame.drop(students,inplace=True)\n",
    "                indeces.append(students)\n",
    "        cohorts[cohort] = [idx for sublist in indeces for idx in sublist]\n",
    "    \n",
    "    if frame.shape[0] > 0:\n",
    "        add_to_each = int(frame.shape[0]/num_cohorts)\n",
    "        for cohort in cohorts:\n",
    "            leftovers = list(frame.sample(n = add_to_each).index.values)\n",
    "            if len(cohorts[cohort]) < size:\n",
    "                for i in leftovers:\n",
    "                    cohorts[cohort].append(i)\n",
    "                frame.drop(leftovers,inplace=True)\n",
    "    \n",
    "    for cohort in cohorts:\n",
    "        if len(cohorts[cohort]) > size:\n",
    "            chop = len(cohorts[cohort]) - size\n",
    "            put_back = cohorts[cohort][-chop:]\n",
    "            cohorts[cohort] = cohorts[cohort][:-chop]\n",
    "            frame = frame.append(df.loc[put_back])\n",
    "#             print(frame.loc[put_back].program)\n",
    "    \n",
    "    if frame.shape[0] > 0:\n",
    "        for i,s in enumerate(frame.index.values):\n",
    "            for cohort in cohorts:\n",
    "                if len(cohorts[cohort]) < size:\n",
    "                    cohorts[cohort].append(s)\n",
    "            frame.drop(s,inplace=True)\n",
    "\n",
    "    return cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "### Actually making the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want some balanced groups and some groups based on (dis)similarity\n",
    "# so lets break up the data\n",
    "balanced = data.sample(frac=.66)\n",
    "smaller = data.drop(balanced.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with making the balanced cohorts\n",
    "balanced_inds = make_balanced_groups(30,balanced,num_cohorts=4)\n",
    "\n",
    "# since the function returns indeces, we have to now associate those indeces with entries in our dataframe\n",
    "bal_cohort_dfs = {}\n",
    "for cohort in balanced_inds:\n",
    "    bal_cohort_dfs['{}'.format(cohort)] = balanced.loc[balanced_inds[cohort]]\n",
    "    \n",
    "# looks like there might have been some duplicates; identify those so we can manually delete them.\n",
    "temp = []\n",
    "for key in balanced_inds:\n",
    "    temp.append(balanced_inds[key])\n",
    "    \n",
    "find_dupes = [idx for sublist in temp for idx in sublist]\n",
    "set([x for x in find_dupes if find_dupes.count(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what we want to do is make two similar cohorts and two mixed cohorts.\n",
    "# in order to preserve the original ratios, we'll use make_balanced_groups \n",
    "# to split this into two balanced groups\n",
    "# and then break those into the actual cohorts.\n",
    "smaller_inds = make_balanced_groups(30,smaller,2)\n",
    "\n",
    "small_cohort_dfs = {}\n",
    "for cohort in smaller_inds:\n",
    "    small_cohort_dfs['{}'.format(cohort)] = smaller.loc[smaller_inds[cohort]]\n",
    "    \n",
    "# similar groups\n",
    "two_small_sim = make_groups(2,small_cohort_dfs['Cohort1'])\n",
    "\n",
    "# mixed groups\n",
    "two_small_mix = make_groups(2,small_cohort_dfs['Cohort2'],\"mix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmluser/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/mmluser/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Now that we have all our cohort assignments, let's merge them into our original dataset so we can download it and do whatever we want in excel, etc.\n",
    "data[\"cohort\"] = [\"\" for i in data.index]\n",
    "\n",
    "#Cohort 1-4: 30 balanced\n",
    "for i in range(1,5):\n",
    "    data.loc[balanced_inds['Cohort{}'.format(i)],\"cohort\"] = i \n",
    "\n",
    "#Cohort 5: 15 similar\n",
    "data.loc[two_small_sim['Cohort0'],\"cohort\"] = 5\n",
    "\n",
    "#Cohort 6: 15 mix\n",
    "data.loc[two_small_mix['Cohort0'],\"cohort\"] = 6\n",
    "\n",
    "#Cohort 7: 15 similar\n",
    "data.loc[two_small_sim['Cohort1'],\"cohort\"] = 7\n",
    "\n",
    "#Cohort 8: 15 mix\n",
    "data.loc[two_small_mix['Cohort1'],\"cohort\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out who didn't sign up\n",
    "signed_up = both.Name.values\n",
    "all_names = info.Name.values\n",
    "\n",
    "didnt = [i for i in all_names if i not in signed_up]\n",
    "didnt_sign_up = info[info.Name.isin(didnt)]\n",
    "didnt_sign_up.drop([40,222,146],inplace=True)\n",
    "# didnt_sign_up.to_csv('DidntEnroll.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
